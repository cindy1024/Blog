---
title: 决策树之ID3
date: 2017-06-08 16:28:27
tags: 有监督学习
categories: 模式识别
mathjax: true
---

<!-- more -->
# 概念
**决策树**是一棵多叉树，每个非叶子节点用一个输入特征标记，每个分支用该特征的一个可能值标记，每个叶节点用类别的一个元素标记。

**决策树算法**，在训练阶段，用样本数据构造一棵决策树，作为分类器。学习的结果是一个决策树。

# 两个问题
## 什么样的特征分类能力最好？
采用熵，作为系统无序化程度的度量。
信息熵：信源不确定度。
$ H \left (U \right) = E \left [ - \log p\_{i} \right ] = - \sum\_{i=1}^{n} p\_{i} \log p\_{i} $
**值得注意的是**，信息集合的体量越大，熵也越大。所以用集合中样本数量的占比来为集合加权，引入信息增益。

信息增益：特征给系统带来的信息量。熵减 = 信息增
$ IG \left ( S , T \right) = E \left( S \right ) - \sum\_{i=0}^{N} \frac{D\_{i}}{D\_{S}} E \left( S\_{i} \right) $

**延伸**
>**互信息** ：变量间相互依赖性的量度
>知道其中一个变量提供的另一个的信息量（即不确定度的减少量）
> ![](http://b.hiphotos.baidu.com/baike/w%3D268%3Bg%3D0/sign=a98b469b259759ee4a5067cd8ac0242b/94cad1c8a786c917de4f70afca3d70cf3ac757d3.jpg)
>知道 X 后 Y 的不确定度的量的减少程度	=	Y的不确定度	-	在 X 已知之后 Y 的剩余不确定度的量

## 怎样的结点是叶子结点？

| 情况 | 判断条件 |
| :---: | :---: |
|纯结点| $ \max IG = 0 $ |
|非纯结点，而且当前所有的特征都测试完| $ \max IG = 0 $ |
|空结点| 样本数 = 0 |

- 对于纯叶子结点，若再用任意特征划分：
对于纯结点集合S，有两种情况，一是样本全属于某类别$ p\_{i} = 1 $，则$ \log\_{2} p\_{i} = 0 $；一是$ p\_{i} = 0 $。此时再用任一特征把S划分为k个子集合$ S\_{1},S\_{2},...,S\_{k} $，全是纯结点，信息熵为零，故$ IG \left ( S , T \right) = E \left( S \right ) - \sum\_{i=0}^{k} \frac{D\_{i}}{D\_{S}} E \left( S\_{i} \right)  = 0 $

- 对于非纯叶结点，所有特征测试完，再选任一特征进行划分：
相当于重复测试特征，得到的子集合 = 父集合。